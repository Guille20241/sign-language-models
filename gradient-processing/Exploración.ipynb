{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "# Step 3.2.2: Pre-Processing\n",
    "def preprocess_image(image):\n",
    "    # Resize the image to 64x64 pixels\n",
    "    resized_image = cv2.resize(image, (64, 64))\n",
    "    return resized_image\n",
    "\n",
    "# Step 3.2.3: Segmentation\n",
    "def segment_image(image):\n",
    "    # Convert the image to the HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Define the lower and upper bounds of the desired color range in HSV space\n",
    "    # Example: Segmenting red color\n",
    "    lower_bound = np.array([0, 58, 50])\n",
    "    upper_bound = np.array([30, 255, 255])\n",
    "    \n",
    "    # Create a mask to isolate the desired color range in HSV space\n",
    "    color_mask_hsv = cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
    "    \n",
    "    # Apply the mask to the original image to segment the desired color\n",
    "    segmented_image = cv2.bitwise_and(image, image, mask=color_mask_hsv)\n",
    "    \n",
    "    return segmented_image\n",
    "\n",
    "# Step 3.2.4: Feature Extraction\n",
    "def extract_features(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(gray_image, 100, 200)\n",
    "    \n",
    "    # Apply the skin color mask to the edge image\n",
    "    # As the image is already segmented, we'll skip this step\n",
    "    \n",
    "    # Compute HOG features for the edge image\n",
    "    hog_features, hog_image = hog(gray_image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), block_norm='L2-Hys',visualize=True)\n",
    "    \n",
    "    # Normalize the HOG features\n",
    "    hog_features = exposure.rescale_intensity(hog_features, in_range=(0, 10))\n",
    "    \n",
    "    return hog_features, hog_image\n",
    "\n",
    "path = r'C:\\Users\\PC\\Documents\\GitHub Repos\\sign-language-models\\synthetic-asl-alphabet\\Train_Alphabet\\A\\0aff0fc7-568a-40a3-b510-0584d817cd01.rgb_0000.png'\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(path)\n",
    "\n",
    "\n",
    "#prep = preprocess_image(image)\n",
    "\n",
    "\n",
    "# Step 1: Segmentation\n",
    "segmented_image = segment_image(image)\n",
    "\n",
    "# Step 2: Feature Extraction\n",
    "#hog_features, hog_image = extract_features(image)   #segmented_image)\n",
    "\n",
    "# Step 3: Model Training and Hyperparameter Tuning\n",
    "# Add the hog_features to a 'data' list and train your model using this data\n",
    "#data = hog_features\n",
    "#data\n",
    "\n",
    "cv2.imshow(\"HOG Image\", segmented_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
